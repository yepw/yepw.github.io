<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yeping Wang's Website</title>

  <meta name="author" content="Yeping Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/favicon.png">
</head>

<body>
  <table
    style="width:100%;max-width:1100px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:1%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: left;">
                    Yeping Wang &nbsp;&nbsp;&nbsp; 
                  </p>
                  <p>I am a Computer Science PhD Candidate at the University of Wisconsin-Madison, advised
                    by <a target="_blank"href="https://gleicher.sites.cs.wisc.edu/">Michael Gleicher</a>.
                    I am currently focused on developing planning and optimization algorithms for both fixed-base and mobile manipulators. I am also interested in human-robot interaction and robot visualization. 
                    Previously, I obtained my Master's degree in Robotics from Johns Hopkins University.
                  </p>
                  <p>In Spring 2025, I am doing an internship at <a target="_blank"href="https://www.merl.com/"> Mitsubishi Electric Research Laboratories (MERL)</a>
                   , where I am working with <a target="_blank"href="https://sites.google.com/site/sdicairano/home"> Stefano Di Cairano
                  </a> and <a target="_blank"href="https://sites.google.com/view/alexanderschperberg/home"> Alexander Schperberg
                  </a> on loco-manipulation.
                    <!-- , where I
                    was supervised by <a target="_blank"href="https://www.cs.jhu.edu/~cmhuang/"> Chien-Ming
                      Huang</a>. -->
                  </p>
                  <p>
                    yeping@cs.wisc.edu
                  </p>
                  <p style="text-align:left">
                    <!-- <a target="_blank"href="mailto:yeping@cs.wisc.edu">Email</a> &nbsp;|&nbsp; -->
                    <a target="_blank"href="Yeping_CV.pdf">CV</a> &nbsp;|&nbsp;
                    <!-- <a target="_blank"href="https://twitter.com/CartSiff">X (Twitter)</a> &nbsp;/&nbsp; -->
                    <a target="_blank"href="https://scholar.google.com/citations?user=j60sH8gAAAAJ&hl=en">Google
                      Scholar</a> &nbsp;|&nbsp;
                    <a target="_blank"href="https://github.com/yepw/">Github</a>
                  </p>
                </td>
                <td style="padding:1%;width:35%;max-width:40%;">
                  <div class="bio-image-cropper">
                    <img style="width:100%;max-width:100%" alt="profile photo" src="images/bio.jpg"
                      class="hoverZoomLink">
                  </div>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <h2>Publications</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="mc_stop()" onmouseover="mc_start()">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/ral24.png' width="265">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a target="_blank"href="TODO">
                    <span class="papertitle"> Motion Comparator: Visual Comparison of Robot Motions </span>
                  </a>
                  <div class="authors">
                    <strong>Yeping Wang</strong>,
                    <a target="_blank"class="other_author" href="https://www.linkedin.com/in/alexander-peseckis/?trk=public_profile_browsemap">Alexander Peseckis</a>,
                    <a target="_blank"class="other_author" href="https://www.linkedin.com/in/zelong-jiang-a8856a23a/">Zelong Jiang</a>,
                    <a target="_blank"class="other_author" href="https://gleicher.sites.cs.wisc.edu/">Michael
                      Gleicher</a>
                  </div>
                  <span class="conf"> RAL, ICRA'25 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <a target="_blank"href="https://arxiv.org/pdf/2407.02746">PDF</a>
                  &nbsp;•&nbsp;
                  <a target="_blank"href="https://github.com/uwgraphics/MotionComparator"> Code </a> </p> 
                  <p></p>
                  <p>We design and build a web-based tool for roboticists to understand, compare, and share robot motions.</p>
                </td>
              </tr>
  

              <tr onmouseout="iklink_stop()" onmouseover="iklink_start()">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='iklink_img' style="transform: translate(0, -40%) "><video width=100% muted autoplay loop>
                        <source src="images/icra24_after.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/icra24_before.png' width="265">
                  </div>
                  <script type="text/javascript">
                    function iklink_start() {
                      document.getElementById('iklink_img').style.opacity = "1";
                    }

                    function iklink_stop() {
                      document.getElementById('iklink_img').style.opacity = "0";
                    }
                    iklink_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a target="_blank"href="https://arxiv.org/abs/2402.16154">
                    <span class="papertitle"><em> IKLink: </em>End-Effector Trajectory Tracking with Minimal
                      Reconfigurations</span>
                  </a>
                  <div class="authors">
                    <strong>Yeping Wang</strong>,
                    <a target="_blank"class="other_author" href="https://cpsiff.github.io/">Carter Sifferman</a>,
                    <a target="_blank"class="other_author" href="https://gleicher.sites.cs.wisc.edu/">Michael
                      Gleicher</a>
                  </div>
                  <span class="conf"> ICRA'24 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <a target="_blank"href="https://arxiv.org/pdf/2402.16154.pdf">PDF</a> &nbsp;•&nbsp;
                  <a target="_blank"href="files/icra24_poster.pdf">Poster</a>&nbsp;•&nbsp;
                  <a target="_blank"href="https://github.com/uwgraphics/iklink">Code</a>
                  <p>A method for tracking end effector trajectories while taking minimal breaks to
                    reconfigure the arm position.</p>
                </td>
              </tr>

              <tr onmouseout="unlock_prox_stop()" onmouseover="unlock_prox_start()">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='unlock_prox_img' style="transform: translate(0, -20%)"><video width=100% muted autoplay loop>
                        <source src="images/ral23_after.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/ral23_before.png' width="265">
                  </div>
                  <script type="text/javascript">
                    function unlock_prox_start() {
                      document.getElementById('unlock_prox_img').style.opacity = "1";
                    }

                    function unlock_prox_stop() {
                      document.getElementById('unlock_prox_img').style.opacity = "0";
                    }
                    unlock_prox_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a target="_blank"href="https://ieeexplore.ieee.org/document/10243076">
                    <span class="papertitle">Unlocking the Performance of Proximity Sensors by
                      Utilizing Transient Histograms</span>
                  </a>
                  <div class="authors">
                    <a target="_blank"class="other_author" href="https://cpsiff.github.io/">Carter Sifferman</a>,
                    <strong>Yeping Wang</strong>,
                    <a target="_blank"class="other_author" href="https://wisionlab.com/people/mohit-gupta/">Mohit
                      Gupta</a>,
                    <a target="_blank"class="other_author" href="https://gleicher.sites.cs.wisc.edu/">Michael
                      Gleicher</a>
                  </div>
                  <span class="conf"> RA-L, ICRA'24 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <a target="_blank"href="https://arxiv.org/pdf/2308.13473.pdf">PDF</a> &nbsp;•&nbsp;
                  <a target="_blank"href="https://cpsiff.github.io/unlocking_proximity_sensors/index.html">Project page</a> &nbsp;•&nbsp;
                  <a target="_blank"href="https://www.youtube.com/watch?v=vJdfpmd6OE0">Video</a> &nbsp;•&nbsp;
                  <a target="_blank"href="https://github.com/uwgraphics/ProximityPlanarRecovery">Code</a>
                  <p></p>
                  <p>We directly utilize low-level information generated by optical time-of-flight sensors to recovery of planar geometry and albedo from a single sensor measurement.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/icra23.jpg' width="265">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a target="_blank"href="https://ieeexplore.ieee.org/document/10161311">
                    <span class="papertitle"><em>RangedIK: </em>An Optimization-Based Robot Motion Generation
                      Method for Ranged-Goal Tasks</span>
                  </a>
                  <div class="authors">
                    <strong>Yeping Wang</strong>,
                    <a target="_blank"class="other_author" href="https://pragathipraveena.com/"> Pragathi Praveena
                    </a>,
                    <a target="_blank"class="other_author" href="https://gleicher.sites.cs.wisc.edu/">Michael
                      Gleicher</a>
                    <br>
                  </div>
                  <span class="conf"> ICRA'23 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <a target="_blank"href="https://arxiv.org/pdf/2302.13935.pdf"> PDF </a>
                  &nbsp;•&nbsp; <a target="_blank"href="https://www.youtube.com/watch?v=-IKy0Yda8p4"> Presentation</a>
                  &nbsp;•&nbsp; <a target="_blank"href="files/icra23_poster.pdf"> Poster </a> 
                  &nbsp;•&nbsp; <a target="_blank"href="https://github.com/uwgraphics/relaxed_ik_core">Code</a>
                </p>

                  <p></p>
                  <p>A real-time motion generation method that accommodates various types
                    of kinematic requirements within
                    a single, unified framework.</p>
                </td>
              </tr>

              <tr onmouseout="rangedik_study_stop()" onmouseover="rangedik_study_start()">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/iros23.jpg' width="265">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a target="_blank"href="https://ieeexplore.ieee.org/document/10342536">
                    <span class="papertitle">Exploiting Task Tolerances in Mimicry-based
                      Telemanipulation</span>
                  </a>
                  <div class="authors">
                    <strong>Yeping Wang</strong>,
                    <a target="_blank"class="other_author" href="https://cpsiff.github.io/">Carter Sifferman</a>,
                    <a target="_blank"class="other_author" href="https://gleicher.sites.cs.wisc.edu/">Michael
                      Gleicher</a>
                  </div>
                  <span class="conf"> IROS'23 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <a target="_blank"href="https://arxiv.org/pdf/2307.15839">PDF</a>
                  &nbsp;•&nbsp;
                  <a target="_blank"href="files/iros23_poster.pdf"> Poster </a> </p>
                  <p></p>
                  <p>We explore task tolerances, i.e., allowable position or rotation inaccuracy, as an important resource to facilitate smooth and effective telemanipulation.</p>
                </td>
              </tr>

              <tr onmouseout="periscope_stop()" onmouseover="periscope_start()">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/cscw23.png' width="265">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a target="_blank"href="https://dl.acm.org/doi/10.1145/3610199">
                    <span class="papertitle">Periscope: A Robotic Camera System to Support Remote
                      Physical Collaboration</span>
                  </a>
                  <div class="authors">
                    <a target="_blank"class="other_author" href="https://pragathipraveena.com/"> Pragathi
                      Praveena</a>,
                    <strong>Yeping Wang</strong>,
                    <a target="_blank"class="other_author" href="https://emmanuel-senft.github.io/"> Emmanuel
                      Senft</a>,
                    <a target="_blank"class="other_author" href="https://gleicher.sites.cs.wisc.edu/">Michael
                      Gleicher</a>,
                    <a target="_blank"class="other_author" href="https://pages.cs.wisc.edu/~bilge/"> Bilge
                      Mutlu</a>
                  </div>
                  <span class="conf"> CSCW'23 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

									<a target="_blank"href="https://arxiv.org/pdf/2305.07517.pdf"> PDF </a>  
                  &nbsp;•&nbsp; <a target="_blank"href="https://project-periscope.github.io/"> Project page </a> 

                    <p></p>
                    <p>We design, build, and evaluate Periscope, a robotic camera system that allows two people to collaborate remotely on physical tasks.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/hri22.png' width="265">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a target="_blank"href="https://ieeexplore.ieee.org/document/9889543">
                    <span class="papertitle">Understanding Control Frames in Multi-Camera Robot Telemanipulation</span>
                  </a>
                  <div class="authors">
                    <a target="_blank"class="other_author" href="https://pragathipraveena.com/"> Pragathi
                      Praveena</a>,
                    Luis Molina,
                    <strong>Yeping Wang</strong>,
                    <a target="_blank"class="other_author" href="https://emmanuel-senft.github.io/"> Emmanuel
                      Senft</a>,
                    <a target="_blank"class="other_author" href="https://pages.cs.wisc.edu/~bilge/"> Bilge
                      Mutlu</a>,
                    <a target="_blank"class="other_author" href="https://gleicher.sites.cs.wisc.edu/">Michael
                      Gleicher</a>
                  </div>
                  <span class="conf"> HRI'22 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <a target="_blank"href="https://graphics.cs.wisc.edu/Papers/2022/PMWSMG22/pmwsmg.pdf"> PDF </a> 
                  &nbsp;•&nbsp;
                  <a target="_blank"href="https://www.youtube.com/watch?v=I70QsswkMFE"> Presentation </a>
                  <p>We investigate the effects of using multiple view-specific
                    control frames in a multi-camera interface on task performance and user
                    experience during robot telemanipulation.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/hri20_fpv_edited.jpg' width="265">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a target="_blank"href="https://dl.acm.org/doi/10.1145/3319502.3374820">
                    <span class="papertitle"> <em> See What I See:</em> Enabling User-Centric Robotic Assistance Using First-Person Demonstrations</span>
                  </a>
                  <div class="authors">
                    <strong>Yeping Wang</strong>,
                    <a target="_blank"class="other_author" href="https://gopikaajaykumar.github.io/"> Gopika Ajaykumar</a>,
                    <a target="_blank"class="other_author" href="https://www.cs.jhu.edu/~cmhuang/"> Chien-Ming Huang</a>,
                  </div>
                  <span class="conf"> HRI'20 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <a target="_blank"href="https://intuitivecomputing.github.io/publications/2020-hri-wang.pdf"> PDF </a> 
                  &nbsp;•&nbsp;
                  <a target="_blank"href="https://www.youtube.com/watch?v=IOwl3GTZI7k"> Presentation </a>
                  <p>We explore how first-person demonstrations can be utilized to enable user-centric robotic assistance 
                    in human-robot collaborative assembly tasks.</p>
                </td>
              </tr>
            </tbody>
          </table>
      <tr>
        <td style="padding:10px;width:75%;vertical-align:middle">
          Website template edited from <a target="_blank"href="https://jonbarron.info//">Jon Barron</a>
        </td>
      </tr>

</body>

</html>